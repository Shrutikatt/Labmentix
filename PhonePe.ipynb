{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PhonePe Transaction Insights**\n",
        "\n",
        "**Project Type** - EDA\n",
        "\n",
        "**Contribution** - Individual"
      ],
      "metadata": {
        "id": "ZEJ-lbqzwxbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary**\n",
        "\n",
        "\n",
        "The **\"PhonePe Transaction Insights\"** project leverages the open-source **PhonePe Pulse dataset**, an extensive repository of anonymized and aggregated digital transaction, user, and insurance data across India. This dataset is categorized into **aggregated**, **map**, and **top** levels, each offering insights at country and state levels, segmented quarterly from 2018 to 2024.\n",
        "\n",
        "The project focuses on **Exploratory Data Analysis (EDA)** to uncover patterns in **digital payment behavior**, including transaction trends over time, top performing states/districts, device preferences among users, and insurance adoption rates. It involves **data extraction, transformation, and visualization** using tools like **Python (Pandas, Matplotlib, Seaborn)** and interactive dashboards via **Streamlit**.\n",
        "\n",
        "Data is sourced from JSON files organized by year and quarter, allowing analysis of how digital payments have evolved across regions and categories. Visualizations include bar charts, pie charts, and line graphs to highlight growth trends, user engagement, and geographical performance.\n",
        "\n",
        "While primarily an EDA project, it holds potential for **regression-based forecasting**, **clustering**, or even **classification** if extended with predictive modeling.\n",
        "\n",
        "This project serves as a powerful tool for stakeholders seeking to understand digital payment dynamics in India and supports **business intelligence, marketing strategy, and policy-making** through actionable visual insights.\n",
        "\n",
        "It aligns with PhonePe’s mission to democratize access to meaningful financial data and encourages developers and analysts to build upon this open dataset for deeper insights.\n"
      ],
      "metadata": {
        "id": "qkvT379IxR7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link**"
      ],
      "metadata": {
        "id": "IUyyAxw3xkfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n",
        "\n",
        "With the increasing reliance on digital payment systems like PhonePe, understanding the dynamics of transactions, user engagement, and insurance-related data is crucial for improving services and targeting users effectively. This project aims to analyze and visualize aggregated values of payment categories, create maps for total values at state and district levels, and identify top-performing states, districts, and pin codes."
      ],
      "metadata": {
        "id": "EFOulZo2xoDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code Implementation**"
      ],
      "metadata": {
        "id": "QiAAfZPNxoc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Clone PhonePe Pulse GitHub Repository"
      ],
      "metadata": {
        "id": "nGqgMsFvdNs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone PhonePe Pulse GitHub Repository\n",
        "!git clone https://github.com/PhonePe/pulse.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KHlSni6dSk7",
        "outputId": "18de0a6e-cd42-4db4-b670-757cce356517"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pulse'...\n",
            "remote: Enumerating objects: 17904, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 17904 (delta 19), reused 17 (delta 17), pack-reused 17855 (from 2)\u001b[K\n",
            "Receiving objects: 100% (17904/17904), 26.13 MiB | 7.67 MiB/s, done.\n",
            "Resolving deltas: 100% (8723/8723), done.\n",
            "Updating files: 100% (9029/9029), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Install Required Libraries"
      ],
      "metadata": {
        "id": "Ex1sSpbudT3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Required Libraries\n",
        "!pip install pandas matplotlib seaborn streamlit plotly openpyxl -q"
      ],
      "metadata": {
        "id": "c8zqOfxIdVnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c43a3f-3fdb-4398-97fc-6e89b43d1fcb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Import Libraries and Setup Paths"
      ],
      "metadata": {
        "id": "pXc-1VK7dYgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries and Define Paths\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "\n",
        "# Set paths\n",
        "DATA_DIR = 'pulse/data'\n",
        "AGGREGATED_DIR = os.path.join(DATA_DIR, 'aggregated')\n",
        "MAP_DIR = os.path.join(DATA_DIR, 'map')\n",
        "TOP_DIR = os.path.join(DATA_DIR, 'top')\n",
        "\n",
        "print(\"Paths set up successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMklii7ddY9L",
        "outputId": "842dbaf4-949e-418d-9f6a-8fc86b3c47e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paths set up successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: ETL Functions to Load Data\n",
        "## 1. Create etl.py file inside /src/"
      ],
      "metadata": {
        "id": "hMkqMRB4desi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File: src/etl.py\n",
        "\n",
        "def load_json_files(base_path):\n",
        "    \"\"\"Load all JSON files from a given directory.\"\"\"\n",
        "    all_data = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.json'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    with open(file_path, 'r') as f:\n",
        "                        data = json.load(f)\n",
        "                        # Add metadata about path\n",
        "                        year = os.path.basename(os.path.dirname(root))\n",
        "                        quarter = os.path.splitext(file)[0]\n",
        "                        data['metadata'] = {'year': year, 'quarter': quarter}\n",
        "                        all_data.append(data)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {file_path}: {e}\")\n",
        "    return all_data\n",
        "\n",
        "\n",
        "def extract_transaction_data(data_list):\n",
        "    \"\"\"Extract transaction data from loaded JSON.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        for entry in data.get('data', {}).get('transactionData', []):\n",
        "            category = entry.get('name', '')\n",
        "            for instrument in entry.get('paymentInstruments', []):\n",
        "                records.append({\n",
        "                    'category': category,\n",
        "                    'count': instrument.get('count', 0),\n",
        "                    'amount': instrument.get('amount', 0),\n",
        "                    'year': meta.get('year'),\n",
        "                    'quarter': meta.get('quarter')\n",
        "                })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_user_device_data(data_list):\n",
        "    \"\"\"Extract user device data.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        aggregated = data.get('data', {}).get('aggregated', {})\n",
        "        users_by_device = data.get('data', {}).get('usersByDevice', [])\n",
        "        for device in users_by_device:\n",
        "            records.append({\n",
        "                'device_brand': device.get('brand'),\n",
        "                'registered_users': device.get('count'),\n",
        "                'percentage': device.get('percentage'),\n",
        "                'total_registered_users': aggregated.get('registeredUsers', 0),\n",
        "                'app_opens': aggregated.get('appOpens', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_map_transaction_data(data_list):\n",
        "    \"\"\"Extract map-level transaction data.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        hover_list = data.get('data', {}).get('hoverDataList', [])\n",
        "        for item in hover_list:\n",
        "            name = item.get('name', '').title()\n",
        "            metric = item.get('metric', [{}])[0]\n",
        "            records.append({\n",
        "                'state_district': name,\n",
        "                'count': metric.get('count', 0),\n",
        "                'amount': metric.get('amount', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_top_states_data(data_list):\n",
        "    \"\"\"Extract top states by transaction volume.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        states = data.get('data', {}).get('states', [])\n",
        "        for state in states:\n",
        "            metric = state.get('metric', {})\n",
        "            records.append({\n",
        "                'state': state.get('entityName', '').title(),\n",
        "                'count': metric.get('count', 0),\n",
        "                'amount': metric.get('amount', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)"
      ],
      "metadata": {
        "id": "dGo_u7qhdgQO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Load All Data into DataFrames"
      ],
      "metadata": {
        "id": "jAfoFGe-dpPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create Required Folders\n"
      ],
      "metadata": {
        "id": "qTXMvf34v7mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Required Folders\n",
        "import os\n",
        "\n",
        "os.makedirs('src', exist_ok=True)\n",
        "\n",
        "print(\"Folder structure created: src/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcJnvIKBev9d",
        "outputId": "22a0cc71-c731-407a-b180-91995a81ba2a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder structure created: src/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create etl.py file"
      ],
      "metadata": {
        "id": "t7esQZOgxdXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create `etl.py` file\n",
        "%%writefile src/etl.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def load_json_files(base_path):\n",
        "    \"\"\"Load all JSON files from a given directory.\"\"\"\n",
        "    all_data = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.json'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    with open(file_path, 'r') as f:\n",
        "                        data = json.load(f)\n",
        "                        # Add metadata about path\n",
        "                        year = os.path.basename(os.path.dirname(root))\n",
        "                        quarter = os.path.splitext(file)[0]\n",
        "                        data['metadata'] = {'year': year, 'quarter': quarter}\n",
        "                        all_data.append(data)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {file_path}: {e}\")\n",
        "    return all_data\n",
        "\n",
        "\n",
        "def extract_transaction_data(data_list):\n",
        "    \"\"\"Extract transaction data from loaded JSON.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        for entry in data.get('data', {}).get('transactionData', []):\n",
        "            category = entry.get('name', '')\n",
        "            for instrument in entry.get('paymentInstruments', []):\n",
        "                records.append({\n",
        "                    'category': category,\n",
        "                    'count': instrument.get('count', 0),\n",
        "                    'amount': instrument.get('amount', 0),\n",
        "                    'year': meta.get('year'),\n",
        "                    'quarter': meta.get('quarter')\n",
        "                })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_user_device_data(data_list):\n",
        "    \"\"\"Extract user device data.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        aggregated = data.get('data', {}).get('aggregated', {})\n",
        "        users_by_device = data.get('data', {}).get('usersByDevice', [])\n",
        "        for device in users_by_device:\n",
        "            records.append({\n",
        "                'device_brand': device.get('brand'),\n",
        "                'registered_users': device.get('count'),\n",
        "                'percentage': device.get('percentage'),\n",
        "                'total_registered_users': aggregated.get('registeredUsers', 0),\n",
        "                'app_opens': aggregated.get('appOpens', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_map_transaction_data(data_list):\n",
        "    \"\"\"Extract map-level transaction data.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        hover_list = data.get('data', {}).get('hoverDataList', [])\n",
        "        for item in hover_list:\n",
        "            name = item.get('name', '').title()\n",
        "            metric = item.get('metric', [{}])[0]\n",
        "            records.append({\n",
        "                'state_district': name,\n",
        "                'count': metric.get('count', 0),\n",
        "                'amount': metric.get('amount', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_top_states_data(data_list):\n",
        "    \"\"\"Extract top states by transaction volume.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        states = data.get('data', {}).get('states', [])\n",
        "        for state in states:\n",
        "            metric = state.get('metric', {})\n",
        "            records.append({\n",
        "                'state': state.get('entityName', '').title(),\n",
        "                'count': metric.get('count', 0),\n",
        "                'amount': metric.get('amount', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aub7XS9mei3c",
        "outputId": "ba5742dc-d3c6-4dee-df42-9ac8cdfcda87"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/etl.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create Folder Structure (src/)\n"
      ],
      "metadata": {
        "id": "aWsOu_662NxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Folder Structure (src/)\n",
        "import os\n",
        "\n",
        "os.makedirs('src', exist_ok=True)\n",
        "\n",
        "print(\"Created folder: src/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDvaXUM1fC68",
        "outputId": "8396de32-fd76-4983-ef44-a85a382ea8f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created folder: src/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Write ETL Module to src/etl.py"
      ],
      "metadata": {
        "id": "sQ9CexUw2VEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write ETL Module to src/etl.py\n",
        "%%writefile src/etl.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def load_json_files(base_path):\n",
        "    \"\"\"Load all JSON files from a given directory.\"\"\"\n",
        "    all_data = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.json'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    with open(file_path, 'r') as f:\n",
        "                        data = json.load(f)\n",
        "                        # Add metadata about path\n",
        "                        year = os.path.basename(os.path.dirname(root))\n",
        "                        quarter = os.path.splitext(file)[0]\n",
        "                        data['metadata'] = {'year': year, 'quarter': quarter}\n",
        "                        all_data.append(data)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {file_path}: {e}\")\n",
        "    return all_data\n",
        "\n",
        "\n",
        "def extract_transaction_data(data_list):\n",
        "    \"\"\"Extract transaction data from loaded JSON.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        for entry in data.get('data', {}).get('transactionData', []):\n",
        "            category = entry.get('name', '')\n",
        "            for instrument in entry.get('paymentInstruments', []):\n",
        "                records.append({\n",
        "                    'category': category,\n",
        "                    'count': instrument.get('count', 0),\n",
        "                    'amount': instrument.get('amount', 0),\n",
        "                    'year': meta.get('year'),\n",
        "                    'quarter': meta.get('quarter')\n",
        "                })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_user_device_data(data_list):\n",
        "    \"\"\"Extract user device data with robust error handling.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        try:\n",
        "            # Ensure metadata exists\n",
        "            meta = data.get(\"metadata\", {})\n",
        "\n",
        "            # Safely get data[\"data\"] with fallback\n",
        "            if not isinstance(data, dict):\n",
        "                continue  # Skip non-dictionary items\n",
        "\n",
        "            data_content = data.get(\"data\")\n",
        "\n",
        "            if not (isinstance(data_content, dict) and data_content):\n",
        "                continue  # Skip if not a non-empty dictionary\n",
        "\n",
        "            aggregated = data_content.get(\"aggregated\", {})\n",
        "            users_by_device = data_content.get(\"usersByDevice\", []) or []\n",
        "\n",
        "            for device in users_by_device:\n",
        "                records.append({\n",
        "                    \"device_brand\": device.get(\"brand\"),\n",
        "                    \"registered_users\": device.get(\"count\"),\n",
        "                    \"percentage\": device.get(\"percentage\"),\n",
        "                    \"total_registered_users\": aggregated.get(\"registeredUsers\", 0),\n",
        "                    \"app_opens\": aggregated.get(\"appOpens\", 0),\n",
        "                    \"year\": meta.get(\"year\"),\n",
        "                    \"quarter\": meta.get(\"quarter\"),\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing one item: {e}\")\n",
        "            continue  # Skip problematic item without breaking loop\n",
        "\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_map_transaction_data(data_list):\n",
        "    \"\"\"Extract map-level transaction data.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        meta = data.get('metadata', {})\n",
        "        hover_list = data.get('data', {}).get('hoverDataList', [])\n",
        "        for item in hover_list:\n",
        "            name = item.get('name', '').title()\n",
        "            metric = item.get('metric', [{}])[0]\n",
        "            records.append({\n",
        "                'state_district': name,\n",
        "                'count': metric.get('count', 0),\n",
        "                'amount': metric.get('amount', 0),\n",
        "                'year': meta.get('year'),\n",
        "                'quarter': meta.get('quarter')\n",
        "            })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "def extract_top_states_data(data_list):\n",
        "    \"\"\"Extract top states by transaction volume with robust error handling.\"\"\"\n",
        "    records = []\n",
        "    for data in data_list:\n",
        "        try:\n",
        "            meta = data.get(\"metadata\", {})\n",
        "\n",
        "            # Safely access nested data\n",
        "            if not isinstance(data, dict):\n",
        "                continue\n",
        "\n",
        "            data_content = data.get(\"data\")\n",
        "            if not (isinstance(data_content, dict) and data_content):\n",
        "                continue\n",
        "\n",
        "            states = data_content.get(\"states\")\n",
        "            if not isinstance(states, list):\n",
        "                states = []\n",
        "\n",
        "            for state in states:\n",
        "                metric = state.get(\"metric\", {})\n",
        "                records.append({\n",
        "                    \"state\": state.get(\"entityName\", \"\").title(),\n",
        "                    \"count\": metric.get(\"count\", 0),\n",
        "                    \"amount\": metric.get(\"amount\", 0),\n",
        "                    \"year\": meta.get(\"year\"),\n",
        "                    \"quarter\": meta.get(\"quarter\"),\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing item: {e}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mth4xWXMfHFA",
        "outputId": "edb92d74-4331-4e94-91cc-3ee900faa22b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/etl.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Import ETL Module and Load Data"
      ],
      "metadata": {
        "id": "uNtbvD3Pl_Qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ETL Module and Load Data\n",
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "# Reload the etl module after modifying it\n",
        "if 'etl' in sys.modules:\n",
        "    del sys.modules['etl']\n",
        "\n",
        "from etl import load_json_files, extract_transaction_data, extract_user_device_data, extract_map_transaction_data, extract_top_states_data\n",
        "\n",
        "# Define base directories\n",
        "DATA_DIR = 'pulse/data'\n",
        "AGGREGATED_DIR = os.path.join(DATA_DIR, 'aggregated')\n",
        "MAP_DIR = os.path.join(DATA_DIR, 'map')\n",
        "TOP_DIR = os.path.join(DATA_DIR, 'top')\n",
        "\n",
        "# --- Load Aggregated Transaction Data ---\n",
        "agg_trans_data = load_json_files(os.path.join(AGGREGATED_DIR, 'transaction'))\n",
        "df_agg_transactions = extract_transaction_data(agg_trans_data)\n",
        "\n",
        "# --- Load Aggregated User Device Data ---\n",
        "agg_user_data = load_json_files(os.path.join(AGGREGATED_DIR, 'user'))\n",
        "df_agg_users = extract_user_device_data(agg_user_data)\n",
        "\n",
        "# --- Load Map-Level Transaction Data ---\n",
        "map_trans_data = load_json_files(os.path.join(MAP_DIR, 'transaction'))\n",
        "df_map_transactions = extract_map_transaction_data(map_trans_data)\n",
        "\n",
        "# --- Load Top States by Transaction Volume ---\n",
        "top_trans_data = load_json_files(os.path.join(TOP_DIR, 'transaction'))\n",
        "df_top_states = extract_top_states_data(top_trans_data)\n",
        "\n",
        "print(\"All data loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRccwriDfPHS",
        "outputId": "2216ab33-a34e-40e2-f4d0-ae3aa9524ab4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All data loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Load All Data into Pandas DataFrames"
      ],
      "metadata": {
        "id": "LJUUeJ5DmEwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load All Data into Pandas DataFrames\n",
        "import sys\n",
        "sys.path.append('src/')\n",
        "from etl import *\n",
        "\n",
        "# Load Aggregated Transaction Data\n",
        "agg_trans_data = load_json_files(os.path.join(AGGREGATED_DIR, 'transaction'))\n",
        "df_agg_transactions = extract_transaction_data(agg_trans_data)\n",
        "\n",
        "# Load User Device Data\n",
        "agg_user_data = load_json_files(os.path.join(AGGREGATED_DIR, 'user'))\n",
        "df_agg_users = extract_user_device_data(agg_user_data)\n",
        "\n",
        "# Load Map Transaction Data\n",
        "map_trans_data = load_json_files(os.path.join(MAP_DIR, 'transaction'))\n",
        "df_map_transactions = extract_map_transaction_data(map_trans_data)\n",
        "\n",
        "# Load Top States Data\n",
        "top_trans_data = load_json_files(os.path.join(TOP_DIR, 'transaction'))\n",
        "df_top_states = extract_top_states_data(top_trans_data)\n",
        "\n",
        "print(\"All dataframes loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P604u43Zdp7F",
        "outputId": "c07fc399-5053-4a75-898f-85486d98ee8e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dataframes loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Data Analysis and Visualization"
      ],
      "metadata": {
        "id": "IWw64mOKdtsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create src/visualization.py (Fully Streamlit-Compatible)\n",
        "%%writefile src/visualization.py\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "\n",
        "# Color scheme\n",
        "PHONEPE_PURPLE = \"#5F0F40\"\n",
        "PHONEPE_RED = \"#9A031E\"\n",
        "PHONEPE_ORANGE = \"#FB8B24\"\n",
        "PHONEPE_DARK_ORANGE = \"#E36414\"\n",
        "PHONEPE_TEAL = \"#0F4C5C\"\n",
        "COLOR_SEQUENCE = [PHONEPE_PURPLE, PHONEPE_RED, PHONEPE_ORANGE, PHONEPE_DARK_ORANGE, PHONEPE_TEAL]\n",
        "\n",
        "# Dark text colors for readability\n",
        "TEXT_COLOR = \"#333333\"\n",
        "AXIS_COLOR = \"#555555\"\n",
        "GRID_COLOR = \"#e0e0e0\"\n",
        "\n",
        "def apply_plot_style(fig, title):\n",
        "    fig.update_layout(\n",
        "        plot_bgcolor='rgba(255, 255, 255, 0.5)',\n",
        "        paper_bgcolor='rgba(255, 255, 255, 0.5)',\n",
        "        title={\n",
        "            'text': f\"<b>{title}</b>\",\n",
        "            'font': {'size': 18, 'color': PHONEPE_PURPLE},\n",
        "            'x': 0.05,\n",
        "            'xanchor': 'left'\n",
        "        },\n",
        "        font={'color': TEXT_COLOR},\n",
        "        xaxis={\n",
        "            'color': AXIS_COLOR,\n",
        "            'gridcolor': GRID_COLOR,\n",
        "            'title_font': {'size': 14}\n",
        "        },\n",
        "        yaxis={\n",
        "            'color': AXIS_COLOR,\n",
        "            'gridcolor': GRID_COLOR,\n",
        "            'title_font': {'size': 14}\n",
        "        },\n",
        "        legend={\n",
        "            'font': {'size': 12},\n",
        "            'title_font': {'size': 13}\n",
        "        },\n",
        "        hoverlabel={\n",
        "            'bgcolor': 'white',\n",
        "            'font_size': 12,\n",
        "            'font_family': \"Arial\",\n",
        "            'bordercolor': PHONEPE_PURPLE\n",
        "        },\n",
        "        margin={'l': 50, 'r': 30, 't': 70, 'b': 50},\n",
        "        hovermode='x unified'\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def plot_transaction_trend(df, return_fig=False):\n",
        "    df['period'] = df['year'] + '-Q' + df['quarter'].astype(str)\n",
        "    grouped = df.groupby('period')[['count', 'amount']].sum().reset_index()\n",
        "\n",
        "    fig = px.line(grouped, x='period', y='count',\n",
        "                 title=\"Transaction Trend Over Time\",\n",
        "                 labels={'count': 'Transaction Count', 'period': 'Quarter'},\n",
        "                 color_discrete_sequence=[PHONEPE_PURPLE],\n",
        "                 template='plotly_white')\n",
        "\n",
        "    fig.update_traces(line_width=3, hovertemplate=\"%{y:,.0f} transactions\")\n",
        "    fig = apply_plot_style(fig, \"Transaction Trend Over Time\")\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "# [Rest of the visualization functions follow the same pattern with the updated styling]\n",
        "\n",
        "def plot_category_distribution(df, return_fig=False):\n",
        "    grouped = df.groupby('category')[['count', 'amount']].sum().reset_index()\n",
        "\n",
        "    fig = px.bar(grouped, x='count', y='category',\n",
        "                 title=\"Transaction Distribution by Category\",\n",
        "                 labels={'count': 'Number of Transactions', 'category': 'Category'},\n",
        "                 color='category',\n",
        "                 color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Transaction Distribution by Category\")\n",
        "    fig.update_yaxes(categoryorder='total ascending')\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_top_states(df, return_fig=False):\n",
        "    grouped = df.groupby('state')[['count', 'amount']].sum().sort_values(by='count', ascending=False).head(10).reset_index()\n",
        "\n",
        "    fig = px.bar(grouped, x='count', y='state',\n",
        "                 title=\"Top 10 States by Transaction Volume\",\n",
        "                 labels={'count': 'Transaction Count', 'state': 'State'},\n",
        "                 color='state',\n",
        "                 color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Top 10 States by Transaction Volume\")\n",
        "    fig.update_yaxes(categoryorder='total ascending')\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_device_usage(df, return_fig=False):\n",
        "    grouped = df.groupby('device_brand')['registered_users'].sum().sort_values(ascending=False).head(10).reset_index()\n",
        "\n",
        "    fig = px.pie(grouped, values='registered_users', names='device_brand',\n",
        "                 title=\"Top 10 Device Brands by User Share\",\n",
        "                 color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Top 10 Device Brands by User Share\")\n",
        "    fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_quarterly_growth(df, return_fig=False):\n",
        "    df['period'] = df['year'] + '-Q' + df['quarter'].astype(str)\n",
        "    grouped = df.groupby('period')['count'].sum().reset_index()\n",
        "    grouped['growth'] = grouped['count'].pct_change() * 100\n",
        "\n",
        "    fig = px.line(grouped, x='period', y='growth',\n",
        "                  title=\"Quarter-over-Quarter Growth Rate\",\n",
        "                  labels={'growth': 'Growth Rate (%)', 'period': 'Quarter'},\n",
        "                  color_discrete_sequence=[PHONEPE_RED])\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Quarter-over-Quarter Growth Rate\")\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\")\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_category_trends(df, return_fig=False):\n",
        "    df['period'] = df['year'] + '-Q' + df['quarter'].astype(str)\n",
        "    grouped = df.groupby(['period', 'category'])['count'].sum().reset_index()\n",
        "\n",
        "    fig = px.line(grouped, x='period', y='count', color='category',\n",
        "                  title=\"Category-wise Transaction Trends\",\n",
        "                  labels={'count': 'Transaction Count', 'period': 'Quarter'},\n",
        "                  color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Category-wise Transaction Trends\")\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_state_analysis(df, return_fig=False):\n",
        "    grouped = df.groupby('state')[['count', 'amount']].sum().reset_index()\n",
        "\n",
        "    fig = px.scatter(grouped, x='count', y='amount', color='state',\n",
        "                     size='count', hover_name='state',\n",
        "                     title=\"State-wise Transaction Volume vs Value\",\n",
        "                     labels={'count': 'Transaction Count', 'amount': 'Transaction Amount'},\n",
        "                     color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"State-wise Transaction Volume vs Value\")\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_top_districts(df, return_fig=False):\n",
        "    grouped = df.groupby('state_district')['count'].sum().sort_values(ascending=False).head(15).reset_index()\n",
        "\n",
        "    fig = px.bar(grouped, x='count', y='state_district',\n",
        "                 title=\"Top 15 Districts by Transaction Volume\",\n",
        "                 labels={'count': 'Transaction Count', 'state_district': 'District'},\n",
        "                 color='state_district',\n",
        "                 color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Top 15 Districts by Transaction Volume\")\n",
        "    fig.update_yaxes(categoryorder='total ascending')\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_user_growth(df, return_fig=False):\n",
        "    df['period'] = df['year'] + '-Q' + df['quarter'].astype(str)\n",
        "    grouped = df.groupby('period')['total_registered_users'].sum().reset_index()\n",
        "\n",
        "    fig = px.line(grouped, x='period', y='total_registered_users',\n",
        "                  title=\"Registered User Growth\",\n",
        "                  labels={'total_registered_users': 'Registered Users', 'period': 'Quarter'},\n",
        "                  color_discrete_sequence=[PHONEPE_TEAL])\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Registered User Growth\")\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_device_share_trend(df, return_fig=False):\n",
        "    df['period'] = df['year'] + '-Q' + df['quarter'].astype(str)\n",
        "    grouped = df.groupby(['period', 'device_brand'])['registered_users'].sum().reset_index()\n",
        "    top_brands = df.groupby('device_brand')['registered_users'].sum().sort_values(ascending=False).head(5).index\n",
        "    grouped = grouped[grouped['device_brand'].isin(top_brands)]\n",
        "\n",
        "    fig = px.area(grouped, x='period', y='registered_users', color='device_brand',\n",
        "                  title=\"Top 5 Device Brands Over Time\",\n",
        "                  labels={'registered_users': 'Registered Users', 'period': 'Quarter'},\n",
        "                  color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Top 5 Device Brands Over Time\")\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_transaction_heatmap(df, return_fig=False):\n",
        "    df['period'] = df['year'] + '-Q' + df['quarter'].astype(str)\n",
        "    grouped = df.groupby(['period', 'category'])['count'].sum().unstack()\n",
        "\n",
        "    fig = px.imshow(grouped,\n",
        "                   labels=dict(x=\"Category\", y=\"Quarter\", color=\"Transactions\"),\n",
        "                   title=\"Transaction Heatmap by Quarter and Category\",\n",
        "                   color_continuous_scale=[PHONEPE_PURPLE, PHONEPE_ORANGE])\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Transaction Heatmap by Quarter and Category\")\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_avg_transaction_value(df, return_fig=False):\n",
        "    grouped = df.groupby('category').agg({'count':'sum', 'amount':'sum'}).reset_index()\n",
        "    grouped['avg_value'] = grouped['amount'] / grouped['count']\n",
        "\n",
        "    fig = px.bar(grouped, x='category', y='avg_value',\n",
        "                 title=\"Average Transaction Value by Category\",\n",
        "                 labels={'avg_value': 'Average Value (₹)', 'category': 'Category'},\n",
        "                 color='category',\n",
        "                 color_discrete_sequence=COLOR_SEQUENCE)\n",
        "\n",
        "    fig = apply_plot_style(fig, \"Average Transaction Value by Category\")\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    st.plotly_chart(fig, use_container_width=True)"
      ],
      "metadata": {
        "id": "aG73gyuLduJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d325ab3d-473d-4da2-a764-9101766aa62f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/visualization.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Run Visualizations"
      ],
      "metadata": {
        "id": "glSIsYH4dwH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run and Save All Visualizations\n",
        "import sys\n",
        "sys.path.append('src/')\n",
        "from visualization import *\n",
        "import os\n",
        "\n",
        "# Create output directory if not exists\n",
        "os.makedirs('output', exist_ok=True)\n",
        "os.makedirs('output/visualizations', exist_ok=True)  # For saving plot images\n",
        "\n",
        "# Function to save Plotly figures as HTML for Streamlit\n",
        "def save_plotly_fig(fig, filename):\n",
        "    fig.write_html(f\"output/visualizations/{filename}.html\")\n",
        "\n",
        "# 1. Transaction Trend\n",
        "fig1 = plot_transaction_trend(df_agg_transactions, return_fig=True)\n",
        "save_plotly_fig(fig1, \"transaction_trend\")\n",
        "\n",
        "# 2. Category Distribution\n",
        "fig2 = plot_category_distribution(df_agg_transactions, return_fig=True)\n",
        "save_plotly_fig(fig2, \"category_distribution\")\n",
        "\n",
        "# 3. Top States\n",
        "fig3 = plot_top_states(df_top_states, return_fig=True)\n",
        "save_plotly_fig(fig3, \"top_states\")\n",
        "\n",
        "# 4. Device Usage\n",
        "fig4 = plot_device_usage(df_agg_users, return_fig=True)\n",
        "save_plotly_fig(fig4, \"device_usage\")\n",
        "\n",
        "# 5. Quarterly Growth\n",
        "fig5 = plot_quarterly_growth(df_agg_transactions, return_fig=True)\n",
        "save_plotly_fig(fig5, \"quarterly_growth\")\n",
        "\n",
        "# 6. Category Trends\n",
        "fig6 = plot_category_trends(df_agg_transactions, return_fig=True)\n",
        "save_plotly_fig(fig6, \"category_trends\")\n",
        "\n",
        "# 7. State Analysis\n",
        "fig7 = plot_state_analysis(df_top_states, return_fig=True)\n",
        "save_plotly_fig(fig7, \"state_analysis\")\n",
        "\n",
        "# 8. Top Districts\n",
        "fig8 = plot_top_districts(df_map_transactions, return_fig=True)\n",
        "save_plotly_fig(fig8, \"top_districts\")\n",
        "\n",
        "# 9. User Growth\n",
        "fig9 = plot_user_growth(df_agg_users, return_fig=True)\n",
        "save_plotly_fig(fig9, \"user_growth\")\n",
        "\n",
        "# 10. Device Share Trends\n",
        "fig10 = plot_device_share_trend(df_agg_users, return_fig=True)\n",
        "save_plotly_fig(fig10, \"device_share_trends\")\n",
        "\n",
        "# 11. Transaction Heatmap\n",
        "fig11 = plot_transaction_heatmap(df_agg_transactions, return_fig=True)\n",
        "save_plotly_fig(fig11, \"transaction_heatmap\")\n",
        "\n",
        "# 12. Avg Transaction Value\n",
        "fig12 = plot_avg_transaction_value(df_agg_transactions, return_fig=True)\n",
        "save_plotly_fig(fig12, \"avg_transaction_value\")\n",
        "\n",
        "# Save DataFrames to CSV for Streamlit\n",
        "df_agg_transactions.to_csv('output/agg_transactions.csv', index=False)\n",
        "df_agg_users.to_csv('output/agg_users.csv', index=False)\n",
        "df_map_transactions.to_csv('output/map_transactions.csv', index=False)\n",
        "df_top_states.to_csv('output/top_states.csv', index=False)\n",
        "\n",
        "print(\"All data and visualizations saved to output/\")"
      ],
      "metadata": {
        "id": "2sfzb9pLdxbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f27a0f-77fd-4fbe-f735-804ebc087f99"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All data and visualizations saved to output/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 10: Save DataFrames for Reuse"
      ],
      "metadata": {
        "id": "o0K-aL8kd3Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DataFrames to CSV\n",
        "df_agg_transactions.to_csv('output/agg_transactions.csv', index=False)\n",
        "df_agg_users.to_csv('output/agg_users.csv', index=False)\n",
        "df_map_transactions.to_csv('output/map_transactions.csv', index=False)\n",
        "df_top_states.to_csv('output/top_states.csv', index=False)\n",
        "\n",
        "print(\"Data saved to output folder.\")"
      ],
      "metadata": {
        "id": "9L0TYtmZd4da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a720b49-19d6-42be-d7b2-d70a7b663565"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 11: Build Streamlit Dashboard"
      ],
      "metadata": {
        "id": "p_JDM3RRd8BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final dashboard.py\n",
        "%%writefile dashboard.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('src/')\n",
        "from visualization import *\n",
        "\n",
        "# Set page config with improved styling\n",
        "st.set_page_config(\n",
        "    page_title=\"PhonePe Pulse Analytics\",\n",
        "    layout=\"wide\",\n",
        "    page_icon=\"📊\"\n",
        ")\n",
        "\n",
        "# PhonePe logo URL (using raw SVG for reliability)\n",
        "PHONEPE_LOGO = \"\"\"\n",
        "<svg width=\"150\" height=\"40\" viewBox=\"0 0 150 40\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
        "<path d=\"M30 10H20V30H30V10Z\" fill=\"#5F0F40\"/>\n",
        "<path d=\"M40 10H30V30H40V10Z\" fill=\"#9A031E\"/>\n",
        "<path d=\"M50 10H40V30H50V10Z\" fill=\"#FB8B24\"/>\n",
        "<path d=\"M60 10H50V30H60V10Z\" fill=\"#E36414\"/>\n",
        "<path d=\"M70 10H60V30H70V10Z\" fill=\"#0F4C5C\"/>\n",
        "<text x=\"80\" y=\"25\" font-family=\"Arial\" font-size=\"20\" font-weight=\"bold\" fill=\"#5F0F40\">PhonePe Pulse</text>\n",
        "</svg>\n",
        "\"\"\"\n",
        "\n",
        "# Apply custom CSS for perfect styling\n",
        "st.markdown(f\"\"\"\n",
        "    <style>\n",
        "        /* Main background */\n",
        "        .main, .stApp {{\n",
        "            background-color: #5F0F40;\n",
        "        }}\n",
        "\n",
        "        /* Text colors */\n",
        "        h1, h2, h3, h4, h5, h6 {{\n",
        "            color: white !important;\n",
        "            font-weight: 600 !important;\n",
        "        }}\n",
        "\n",
        "        /* Sidebar styling */\n",
        "        .css-1lcbmhc {{\n",
        "            background-color: #5F0F40 !important;\n",
        "        }}\n",
        "        .css-1lcbmhc h1,\n",
        "        .css-1lcbmhc .stRadio label {{\n",
        "            color: white !important;\n",
        "        }}\n",
        "\n",
        "        /* Chart background */\n",
        "        .stPlotlyChart, .plot-container {{\n",
        "            background-color: rgba(0, 0, 0, 0.5);\n",
        "            border-radius: 8px;\n",
        "            padding: 15px;\n",
        "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "        }}\n",
        "\n",
        "        /* Navigation radio buttons */\n",
        "        .stRadio div[role=\"radiogroup\"] {{\n",
        "            background-color: #6c1d5f;\n",
        "            padding: 10px;\n",
        "            border-radius: 8px;\n",
        "        }}\n",
        "        .stRadio label {{\n",
        "            color: white !important;\n",
        "            padding: 5px 10px;\n",
        "        }}\n",
        "        .stRadio label:hover {{\n",
        "            background-color: #9A031E !important;\n",
        "        }}\n",
        "\n",
        "        /* Remove the 0 below logo */\n",
        "        .css-1v3fvcr {{\n",
        "            display: none;\n",
        "        }}\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Main title\n",
        "st.title(\"📊 PhonePe Pulse Analytics Dashboard\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Sidebar navigation with proper logo\n",
        "with st.sidebar:\n",
        "    st.markdown(PHONEPE_LOGO, unsafe_allow_html=True)\n",
        "    st.markdown(\"<h1 style='color:white !important;'>Navigation</h1>\", unsafe_allow_html=True)\n",
        "    option = st.radio(\n",
        "        \"Menu\",\n",
        "        [\n",
        "            \"Overview\",\n",
        "            \"Transaction Analysis\",\n",
        "            \"User Analysis\",\n",
        "            \"Geographical Analysis\",\n",
        "            \"Advanced Insights\"\n",
        "        ],\n",
        "        index=0,\n",
        "        label_visibility=\"collapsed\"\n",
        "    )\n",
        "\n",
        "# Load data\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    return {\n",
        "        'agg_transactions': pd.read_csv('output/agg_transactions.csv'),\n",
        "        'agg_users': pd.read_csv('output/agg_users.csv'),\n",
        "        'map_transactions': pd.read_csv('output/map_transactions.csv'),\n",
        "        'top_states': pd.read_csv('output/top_states.csv')\n",
        "    }\n",
        "\n",
        "data = load_data()\n",
        "\n",
        "# Overview Page\n",
        "if option == \"Overview\":\n",
        "    st.subheader(\"📌 Key Insights at a Glance\")\n",
        "\n",
        "    # Create metrics row\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "    total_trans = data['agg_transactions']['count'].sum()\n",
        "    total_users = data['agg_users']['total_registered_users'].sum()\n",
        "    avg_trans = data['agg_transactions']['amount'].sum() / data['agg_transactions']['count'].sum()\n",
        "    top_state = data['top_states'].groupby('state')['count'].sum().idxmax()\n",
        "\n",
        "    col1.metric(\"Total Transactions\", f\"{total_trans:,.0f}\")\n",
        "    col2.metric(\"Total Registered Users\", f\"{total_users:,.0f}\")\n",
        "    col3.metric(\"Avg. Transaction Value\", f\"₹{avg_trans:,.2f}\")\n",
        "    col4.metric(\"Top Performing State\", top_state)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Show important charts in overview\n",
        "    st.subheader(\"📈 Key Transaction Trends\")\n",
        "    plot_transaction_trend(data['agg_transactions'])\n",
        "\n",
        "    st.subheader(\"📱 Top Device Brands\")\n",
        "    plot_device_usage(data['agg_users'])\n",
        "\n",
        "    st.subheader(\"🏆 Top Performing States\")\n",
        "    plot_top_states(data['top_states'])\n",
        "\n",
        "# Transaction Analysis Page\n",
        "elif option == \"Transaction Analysis\":\n",
        "    st.subheader(\"💸 Transaction Analysis\")\n",
        "\n",
        "    tab1, tab2, tab3 = st.tabs([\"Trends\", \"Categories\", \"Metrics\"])\n",
        "\n",
        "    with tab1:\n",
        "        st.subheader(\"Transaction Volume Over Time\")\n",
        "        plot_transaction_trend(data['agg_transactions'])\n",
        "\n",
        "        st.subheader(\"Quarterly Growth Rates\")\n",
        "        plot_quarterly_growth(data['agg_transactions'])\n",
        "\n",
        "    with tab2:\n",
        "        st.subheader(\"Transaction Distribution by Category\")\n",
        "        plot_category_distribution(data['agg_transactions'])\n",
        "\n",
        "        st.subheader(\"Category Trends Over Time\")\n",
        "        plot_category_trends(data['agg_transactions'])\n",
        "\n",
        "    with tab3:\n",
        "        st.subheader(\"Average Transaction Values\")\n",
        "        plot_avg_transaction_value(data['agg_transactions'])\n",
        "\n",
        "        st.subheader(\"Transaction Heatmap\")\n",
        "        plot_transaction_heatmap(data['agg_transactions'])\n",
        "\n",
        "# User Analysis Page\n",
        "elif option == \"User Analysis\":\n",
        "    st.subheader(\"👥 User Behavior Analysis\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        st.subheader(\"User Growth Over Time\")\n",
        "        plot_user_growth(data['agg_users'])\n",
        "\n",
        "        st.subheader(\"Top Device Brands\")\n",
        "        plot_device_usage(data['agg_users'])\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Device Brand Trends\")\n",
        "        plot_device_share_trend(data['agg_users'])\n",
        "\n",
        "# Geographical Analysis Page\n",
        "elif option == \"Geographical Analysis\":\n",
        "    st.subheader(\"🌍 Geographical Distribution\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        st.subheader(\"Top Performing States\")\n",
        "        plot_top_states(data['top_states'])\n",
        "\n",
        "        st.subheader(\"State Performance Analysis\")\n",
        "        plot_state_analysis(data['top_states'])\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Top Districts by Volume\")\n",
        "        plot_top_districts(data['map_transactions'])\n",
        "\n",
        "# Advanced Insights Page\n",
        "elif option == \"Advanced Insights\":\n",
        "    st.subheader(\"🔍 Advanced Analytics\")\n",
        "\n",
        "    st.subheader(\"Transaction Category Trends\")\n",
        "    plot_category_trends(data['agg_transactions'])\n",
        "\n",
        "    st.subheader(\"Device Brand Evolution\")\n",
        "    plot_device_share_trend(data['agg_users'])\n",
        "\n",
        "    st.subheader(\"Transaction Value Analysis\")\n",
        "    plot_avg_transaction_value(data['agg_transactions'])\n",
        "\n",
        "    st.subheader(\"Quarterly Performance Heatmap\")\n",
        "    plot_transaction_heatmap(data['agg_transactions'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXXA5tSjV2b7",
        "outputId": "e6c5bebd-9892-4293-f7e4-6dd32f27c741"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dashboard.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 12: Launch Streamlit Dashboard"
      ],
      "metadata": {
        "id": "ezVrIoJunwAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing pyngrok package - enables creating secure tunnels to localhost via ngrok\n",
        "\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93YBdTsP5HUI",
        "outputId": "34954036-45c9-48be-c5c5-df6d703c7583"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get the ngrok authtoken from Colab secrets\n",
        "NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "else:\n",
        "    print(\"NGROK_AUTH_TOKEN not found in Colab secrets. Please add it.\")\n",
        "\n",
        "\n",
        "# Run Streamlit in the background\n",
        "!streamlit run dashboard.py &>/dev/null&\n",
        "\n",
        "# Get the public URL\n",
        "public_url = ngrok.connect(addr='8501')\n",
        "print(\"Streamlit Dashboard URL:\")\n",
        "print(public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1hueiH25L6o",
        "outputId": "77a422a2-eae7-4714-8cfe-530fdf3efc6f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit Dashboard URL:\n",
            "NgrokTunnel: \"https://bb2c4f1b2cbe.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "W5bkxVpmyEWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **PhonePe Transaction Insights** project leverages the open-source **PhonePe Pulse dataset** to perform **Exploratory Data Analysis (EDA)** on digital payment trends in India. It analyzes transaction, user, and insurance data across states, districts, and time periods to uncover patterns and regional performance. Using **Python**, **Pandas**, and **Streamlit**, it builds an interactive dashboard for visualizing key metrics like transaction volume, device usage, and top-performing regions. The project supports strategic decision-making for marketing, policy-making, and financial inclusion by transforming complex JSON data into meaningful insights through **data visualization** and structured analysis."
      ],
      "metadata": {
        "id": "uA-TjM09nhxk"
      }
    }
  ]
}